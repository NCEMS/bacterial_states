#Snakefile for NCEMS inGEST RNA-seq pipeline designed by Alexis Morrissey (contact on github)

#Getting config information
configfile: "config.yaml"
experiment_name = config.get("experiment", "experiment_unknown")
annotation_gff = config.get("annotation_gff")
annotation_bed = config.get("annotation_bed")
gref = config.get("ref")
vg_index = config.get("vg_index")

import json
deseq2_contrasts = config.get("deseq2", {}).get("contrasts", [])
contrast_names = []
for cont in deseq2_contrasts:
    factor, ref, test = cont
    contrast_names.append(f"{ref}_vs_{test}")
    

#Generate metadata for DESeq2 comparisons
rule generate_sample_metadata:
    output:
        temp(f"{experiment_name}_results/sample_metadata.tsv")
    run:
        import pandas as pd

        samples = config["samples"]
        metadata = []

        for sample_id, info in samples.items():
            row = {"sample_id": sample_id}
            row["condition"] = info.get("condition", "NA")
            if "condition2" in info:
                row["condition2"] = info["condition2"]
            metadata.append(row)

        df = pd.DataFrame(metadata)
        df.to_csv(output[0], sep="\t", index=False)

#Determine if any sample is paired-end
SAMPLES = config.get("samples", {})
SE = all("r2" not in SAMPLES[s] for s in SAMPLES)


##########################Single-end Rules
if SE:
    #Trimming and low quality reads removed
    rule fastp_se:
        input:
            r1=lambda wildcards: SAMPLES[wildcards.sample]["r1"]
        output:
            temp(f"{experiment_name}_results/{{sample}}/{{sample}}_clean_R1.fastq"),
            html=f"{experiment_name}_results/{{sample}}/fastp/{{sample}}_fastp.html",
            json=f"{experiment_name}_results/{{sample}}/fastp/{{sample}}_fastp.json"
        threads: 12
        shell:
            """
            fastp -i {input.r1} -o {output[0]} \\
            -h {output.html} -j {output.json} -w {threads}
            """

    #Sequencing QC check
    rule fastqc_se:
        input:
            r1=f"{experiment_name}_results/{{sample}}/{{sample}}_clean_R1.fastq"
        output:
            html=f"{experiment_name}_results/{{sample}}/fastqc/{{sample}}_clean_R1_fastqc.html",
            zip=f"{experiment_name}_results/{{sample}}/fastqc/{{sample}}_clean_R1_fastqc.zip"
        shell:
            "fastqc {input.r1} -o {experiment_name}_results/{wildcards.sample}/fastqc"

    #Contamination check
    rule centrifuge_se:
        input:
            r1 = f"{experiment_name}_results/{{sample}}/{{sample}}_clean_R1.fastq",
        output:
            temp_report = temp(f"{experiment_name}_results/{{sample}}/centrifuge/initial.tsv"),
            temp_reads = temp(f"{experiment_name}_results/{{sample}}/centrifuge/good_read.txt"),
            temp_fastq = temp(f"{experiment_name}_results/{{sample}}/centrifuge/_unambiguous.fastq"),
            tsv       = temp(f"{experiment_name}_results/{{sample}}/centrifuge/{{sample}}_output.tsv"),
            report  = f"{experiment_name}_results/{{sample}}/centrifuge/{{sample}}_report.txt",
        params:
            db = "../resources/centrifuge/p_compressed+h+v",
        threads: 12
        shell:
            r"""
            mkdir -p {experiment_name}_results/{wildcards.sample}/centrifuge
            centrifuge -x {params.db} -U {input.r1} -S {output.temp_report} -p {threads} >/dev/null 2>&1
            #Picking reads with a species assignment
            awk 'NR>1 && $3!=0 && $8==1 {{print $1}}' {output.temp_report} | sort -u > {output.temp_reads}
            awk 'BEGIN {{ while ((getline < "{output.temp_reads}")>0) keep[$1]=1 }} NR%4==1 {{ rid=substr($1,2); keep_read=(rid in keep) }} keep_read {{print}}' {input.r1} > {output.temp_fastq}
            #Rerunning centrifuge on reads that have species assignment (not ambiguous)
            centrifuge -x {params.db} -U {output.temp_fastq} -S {output.tsv} -p {threads} >/dev/null 2>&1
            centrifuge-kreport -x {params.db} {output.tsv} > {output.report}
            """

    #Alignment with vg
    rule vg_giraffe_se:
        input:
            r1=f"{experiment_name}_results/{{sample}}/{{sample}}_clean_R1.fastq"
        output:
            gam=f"{experiment_name}_results/{{sample}}/vg/{{sample}}.gam"
        params:
            graph=vg_index+".d2.gbz",
            dist=vg_index+".d2.dist",
            min=vg_index+".d2.min"
        threads: 12
        shell:
            """
            mkdir -p {experiment_name}_results/{wildcards.sample}/vg
            vg giraffe -Z {params.graph} -f {input.r1} -d {params.dist} -m {params.min} -t {threads} -o GAM > {output.gam}
            """

    #Surjecting alignments to K-12 for annotation purposes
    rule vg_surject_se:
        input:
            gam=f"{experiment_name}_results/{{sample}}/vg/{{sample}}.gam"
        output:
            bam=temp(f"{experiment_name}_results/{{sample}}/vg/{{sample}}.bam")
        params:
            graph= vg_index + ".d2.gbz",
            gref= gref,
            strip_prefix= "#".join(gref.split("#")[:-1]) + "#"
        threads: 12
        shell:
            """
            vg surject -x {params.graph} -b -p {params.gref} -t {threads} {input.gam} | \\
            samtools view -h - | \\
            sed 's/{params.strip_prefix}//g' | \\
            samtools view -b - > {output.bam}
            """

else:
    #Trimming and low quality reads removed
    rule fastp_pe:
        input:
            r1=lambda wildcards: SAMPLES[wildcards.sample]["r1"],
            r2=lambda wildcards: SAMPLES[wildcards.sample]["r2"]
        output:
            r1=temp(f"{experiment_name}_results/{{sample}}/{{sample}}_clean_R1.fastq"),
            r2=temp(f"{experiment_name}_results/{{sample}}/{{sample}}_clean_R2.fastq"),
            html=f"{experiment_name}_results/{{sample}}/fastp/{{sample}}_fastp.html",
            json=f"{experiment_name}_results/{{sample}}/fastp/{{sample}}_fastp.json"
        threads: 12
        shell:
            """
            mkdir -p {experiment_name}_results/{wildcards.sample}/fastp
            fastp -i {input.r1} -I {input.r2} -o {output.r1} -O {output.r2} -h {output.html} -j {output.json} -w {threads}
            """

    #Sequencing QC check
    rule fastqc_pe:
        input:
            r1=f"{experiment_name}_results/{{sample}}/{{sample}}_clean_R1.fastq",
            r2=f"{experiment_name}_results/{{sample}}/{{sample}}_clean_R2.fastq"
        output:
            r1_html=f"{experiment_name}_results/{{sample}}/fastqc/{{sample}}_clean_R1_fastqc.html",
            r1_zip=f"{experiment_name}_results/{{sample}}/fastqc/{{sample}}_clean_R1_fastqc.zip",
            r2_html=f"{experiment_name}_results/{{sample}}/fastqc/{{sample}}_clean_R2_fastqc.html",
            r2_zip=f"{experiment_name}_results/{{sample}}/fastqc/{{sample}}_clean_R2_fastqc.zip"
        shell:
            r"""
            mkdir -p {experiment_name}_results/{wildcards.sample}/fastqc
            fastqc {input.r1} -o {experiment_name}_results/{wildcards.sample}/fastqc
            fastqc {input.r2} -o {experiment_name}_results/{wildcards.sample}/fastqc
            """


    #Contamination check
    rule centrifuge_pe:
        input:
            r1 = f"{experiment_name}_results/{{sample}}/{{sample}}_clean_R1.fastq",
            r2 = f"{experiment_name}_results/{{sample}}/{{sample}}_clean_R2.fastq"
        output:
            temp_report = temp(f"{experiment_name}_results/{{sample}}/centrifuge/initial.tsv"),
            temp_reads = temp(f"{experiment_name}_results/{{sample}}/centrifuge/good_reads.txt"),
            temp_fastq_r1 = temp(f"{experiment_name}_results/{{sample}}/centrifuge/clean_R1_unambiguous.fastq"),
            temp_fastq_r2 = temp(f"{experiment_name}_results/{{sample}}/centrifuge/clean_R2_unambiguous.fastq"),
            tsv       = temp(f"{experiment_name}_results/{{sample}}/centrifuge/{{sample}}_output.tsv"),
            report  = f"{experiment_name}_results/{{sample}}/centrifuge/{{sample}}_report.txt"
        params:
            db = "../resources/centrifuge/p_compressed+h+v",
        threads: 12
        shell:
            r"""
            mkdir -p {experiment_name}_results/{wildcards.sample}/centrifuge
            centrifuge -x {params.db} -1 {input.r1} -2 {input.r2} -S {output.temp_report} -p {threads} >/dev/null 2>&1
            #Picking reads with a species assignment
            awk 'NR>1 && $3!=0 && $8==1 {{print $1}}' {output.temp_report} | sort -u > {output.temp_reads}
            awk 'BEGIN {{ while ((getline < "{output.temp_reads}")>0) keep[$1]=1 }} NR%4==1 {{ rid=substr($1,2); keep_read=(rid in keep) }} keep_read {{print}}' {input.r1} > {output.temp_fastq_r1}
            awk 'BEGIN {{ while ((getline < "{output.temp_reads}")>0) keep[$1]=1 }} NR%4==1 {{ rid=substr($1,2); keep_read=(rid in keep) }} keep_read {{print}}' {input.r2} > {output.temp_fastq_r2}
            #Rerunning centrifuge on reads that have species assignment (not ambiguous)
            centrifuge -x {params.db} -1 {output.temp_fastq_r1} -2 {output.temp_fastq_r2} -S {output.tsv} -p {threads} >/dev/null 2>&1
            centrifuge-kreport -x {params.db} {output.tsv} > {output.report}
            """

    #Alignment
    rule vg_giraffe_pe:
        input:
            r1=f"{experiment_name}_results/{{sample}}/{{sample}}_clean_R1.fastq",
            r2=f"{experiment_name}_results/{{sample}}/{{sample}}_clean_R2.fastq"
        output:
            gam=f"{experiment_name}_results/{{sample}}/vg/{{sample}}.gam"
        params:
            graph=vg_index+".d2.gbz",
            dist=vg_index+".d2.dist",
            min=vg_index+".d2.min"
        threads: 12
        shell:
            """
            mkdir -p {experiment_name}_results/{wildcards.sample}/vg
            vg giraffe -Z {params.graph} -f {input.r1} -f {input.r2} -d {params.dist} -m {params.min} -t {threads} -o GAM > {output.gam}
            """

    #Surjecting alignments to K-12 for annotation purposes
    rule vg_surject_pe:
        input:
            gam=f"{experiment_name}_results/{{sample}}/vg/{{sample}}.gam"
        output:
            bam=temp(f"{experiment_name}_results/{{sample}}/vg/{{sample}}.bam")
        params:
            graph= vg_index + ".d2.gbz",
            gref= gref,
            strip_prefix= "#".join(gref.split("#")[:-1]) + "#"
        threads: 12
        shell:
            """
            vg surject -x {params.graph} -b -i -p {params.gref} -t {threads} {input.gam} | \\
            samtools view -h - | \\
            sed 's/{params.strip_prefix}//g' | \\
            samtools view -b - > {output.bam}
            """


#Quanification of read counts for all samples at once
rule featurecounts_combined:
    input:
        bams=expand(f"{experiment_name}_results/{{sample}}/vg/{{sample}}_sort.bam", sample=list(SAMPLES.keys())),
        infer_experiment_for_strand=f"{experiment_name}_results/{list(SAMPLES.keys())[0]}/rseqc/{list(SAMPLES.keys())[0]}_infer_experiment.txt"
    output:
        counts=f"{experiment_name}_results/all_samples_raw_counts.txt",
        summary=f"{experiment_name}_results/all_samples_raw_counts.txt.summary",
        temp_gff=temp(f"{experiment_name}_results/featurecounts_temp_gff")
    params:
        pe_param = "-p" if not SE else ""
    shell:
        r"""
        mkdir -p $(dirname {output.counts})
    
        strand=$(awk '
          /1\+\+,1--/ || /\+\+,--/ {{ strand1 = $NF + 0 }}
          /1\+-,1-\+/ || /\+\-,-\+/ {{ strand2 = $NF + 0 }}
          END {{
            if (strand1 > 80) print 1;
            else if (strand2 > 80) print 2;
            else print 0;
          }}' {input.infer_experiment_for_strand})
    
        if [ "$strand" -eq 0 ]; then
            grep -v "ncRNA" {annotation_gff} > {output.temp_gff}
            featureCounts -a {output.temp_gff} -o {output.counts} -t gene -g Dbxref -s 0 {params.pe_param} {input.bams}
        else
            awk -F"\t" 'BEGIN{{OFS="\t"}} $3=="gene" && $9 ~ /gene_biotype=ncRNA/ {{next}} {{if($3=="ncRNA") $3="gene"; print}}' {annotation_gff} > {output.temp_gff}
            featureCounts -a {output.temp_gff} -o {output.counts} -t gene -g Dbxref -s "$strand" {params.pe_param} {input.bams}
        fi
        """

#Getting statistics for vg alignment
rule vg_stats:
    input:
        gam=f"{experiment_name}_results/{{sample}}/vg/{{sample}}.gam"
    output:
        txt=f"{experiment_name}_results/{{sample}}/vg/{{sample}}_giraffe.stats.txt"
    #Add time information at end to meet multiqc requirements
    shell:
        """
        vg stats -a {input.gam} > {output.txt}
        echo "Total time: 123 seconds" >> {output.txt}
        echo "Speed: 123 reads/second" >> {output.txt}
        """

#Getting strandedness information for sequencing library (used by multiqc)
rule rseqc:
    input:
        bam = f"{experiment_name}_results/{{sample}}/vg/{{sample}}.bam"
    output:
        infer_experiment = f"{experiment_name}_results/{{sample}}/rseqc/{{sample}}_infer_experiment.txt",
        genebody_cov_txt = f"{experiment_name}_results/{{sample}}/rseqc/{{sample}}_genebody_cov.geneBodyCoverage.txt",
        genebody_cov_r = f"{experiment_name}_results/{{sample}}/rseqc/{{sample}}_genebody_cov.geneBodyCoverage.r",
        sorted_bam = f"{experiment_name}_results/{{sample}}/vg/{{sample}}_sort.bam",
        bam_index = f"{experiment_name}_results/{{sample}}/vg/{{sample}}_sort.bam.bai"
    params:
        annotation_bed = config["annotation_bed"]
    shell:
        r"""
        mkdir -p {experiment_name}_results/{wildcards.sample}/rseqc
        infer_experiment.py -i {input.bam} -r {params.annotation_bed} > {output.infer_experiment}
        samtools sort {input.bam} > {output.sorted_bam}
        samtools index {output.sorted_bam}
        geneBody_coverage.py -r <(grep "gene" {params.annotation_bed}) -i {output.sorted_bam} -o {experiment_name}_results/{wildcards.sample}/rseqc/{wildcards.sample}_genebody_cov
        """

#Annotating the combined counts file with metadata from NCBI
rule annotate_counts:
    input:
        counts=f"{experiment_name}_results/all_samples_raw_counts.txt"
    output:
        extended=f"{experiment_name}_results/all_samples_counts_extended.tsv",
        clean=f"{experiment_name}_results/all_samples_gene_symbols.tsv"
    shell:
        """
        mkdir -p {experiment_name}_results/featurecounts
        bash scripts/get_metadata.sh {input.counts} > {output.extended}
        awk 'NR == 1 || $2 != "Geneid"' {output.extended} | cut -f1,4- > {output.clean}
        """

#Custom addition to multiqc, have to keep mqc name or it will not be parsed
rule feature_overlap:
    input:
        bam = f"{experiment_name}_results/{{sample}}/vg/{{sample}}.bam"
    output:
        feature_overlap = f"{experiment_name}_results/{{sample}}/feature_overlap/{{sample}}_feature_overlap_mqc.tsv"
    shell:
        """
        mkdir -p {experiment_name}_results/{wildcards.sample}/feature_overlap
        bash scripts/gene_type.sh {annotation_bed} {input.bam} {output.feature_overlap}
        """

#Running DEseq using comparison listed in config file
rule run_deseq2:
    input:
        counts=f"{experiment_name}_results/all_samples_gene_symbols.tsv",
        metadata=f"{experiment_name}_results/sample_metadata.tsv",
        extended=f"{experiment_name}_results/all_samples_counts_extended.tsv"
    output:
        pca_coords=f"{experiment_name}_results/deseq2/pca_coordinates.tsv",
        pca_plot=f"{experiment_name}_results/deseq2/pca_plot.png",
        pca_mqc = f"{experiment_name}_results/deseq2/pca_mqc.tsv",
        norm_counts=f"{experiment_name}_results/deseq2/normalized_counts.tsv",
        # This expands correctly using ref_vs_test from contrast_names
        results = expand(f"{experiment_name}_results/deseq2/{{contrast}}_deseq_results.tsv", contrast=contrast_names),
        results_summary = expand(f"{experiment_name}_results/deseq2/{{contrast}}_deseq_results_summary.tsv", contrast=contrast_names)
    params:
        outdir=f"{experiment_name}_results/deseq2",
        contrasts_json=json.dumps(deseq2_contrasts) 
    shell:
        """
        mkdir -p {params.outdir}

        Rscript scripts/run_deseq2.R \\
            {input.counts} \\
            {input.metadata} \\
            {params.outdir} \\
            '{params.contrasts_json}'

        # Existing shell commands for post-processing:
        cat scripts/pca_header.txt <(
            echo -e "id\\tPC1\\tPC2\\tcondition"
            sed '1d' {output.pca_coords} | awk 'BEGIN{{OFS="\\t"}} {{print $1, $2, $3, $NF}}'
        ) > {output.pca_mqc}
        for result_file in {params.outdir}/*_deseq_results.tsv; do
            summary_file="${{result_file%.tsv}}_summary.tsv"
            awk 'BEGIN{{FS=OFS="\\t"}}
                  NR==FNR && FNR>1 {{id[$1]=$2; summary[$1]=$3; next}}
                  FNR==1 {{print $0, "Gene_IDs_Field", "Gene_Summary"; next}}
                  FNR>1 {{print $0, id[$1], summary[$1]}}
                  ' {input.extended} "$result_file" > "$summary_file"
        done
        """


#Getting list of expected inputs for multiqc
multiqc_inputs_template = {
    "fastp": f"{experiment_name}_results/{{sample}}/fastp/{{sample}}_fastp.json",
    "fastqc_r1": f"{experiment_name}_results/{{sample}}/fastqc/{{sample}}_clean_R1_fastqc.zip",
    "centrifuge_report": f"{experiment_name}_results/{{sample}}/centrifuge/{{sample}}_report.txt",
    "vg_stats": f"{experiment_name}_results/{{sample}}/vg/{{sample}}_giraffe.stats.txt",
    "rseqc_infer_experiment": f"{experiment_name}_results/{{sample}}/rseqc/{{sample}}_infer_experiment.txt",
    "feature_overlap": f"{experiment_name}_results/{{sample}}/feature_overlap/{{sample}}_feature_overlap_mqc.tsv",
    "pca": f"{experiment_name}_results/deseq2/pca_mqc.tsv"
}

multiqc_all_inputs = []
for sample_name in SAMPLES:
    sample_inputs_dict = {k: v.format(sample=sample_name) for k, v in multiqc_inputs_template.items()}
    if SAMPLES[sample_name].get("r2"):
        sample_inputs_dict["fastqc_r2"] = f"{experiment_name}_results/{sample_name}/fastqc/{sample_name}_clean_R2_fastqc.zip"
    multiqc_all_inputs.extend(list(sample_inputs_dict.values())) 
    
multiqc_all_inputs.append(f"{experiment_name}_results/all_samples_raw_counts.txt.summary")


#Creating QC html with multiqc
rule multiqc:
    input:
        multiqc_all_inputs
    output:
        html=f"{experiment_name}_results/multiqc_report.html"
    params:
        results_dir=f"{experiment_name}_results/"
    shell:
        f"multiqc {params.results_dir} -o {params.results_dir} -c scripts/multiqc_config.yaml --filename multiqc_report.html"
        

#Expected outputs
rna_seq_outputs = []
for sample_name in SAMPLES:
    results_prefix_sample = f"{experiment_name}_results/{sample_name}"
    outputs = [
        f"{results_prefix_sample}/fastqc/{sample_name}_clean_R1_fastqc.zip",
        f"{results_prefix_sample}/fastp/{sample_name}_fastp.json",
        f"{results_prefix_sample}/vg/{sample_name}.gam",
        f"{results_prefix_sample}/vg/{sample_name}_sort.bam",
        f"{results_prefix_sample}/vg/{sample_name}_giraffe.stats.txt",
        f"{results_prefix_sample}/rseqc/{sample_name}_infer_experiment.txt",
        f"{results_prefix_sample}/feature_overlap/{sample_name}_feature_overlap_mqc.tsv"
    ]
    if SAMPLES[sample_name].get("r2"):
        outputs.append(f"{results_prefix_sample}/fastqc/{sample_name}_clean_R2_fastqc.zip")
    rna_seq_outputs.extend(outputs)

#Add the combined outputs
rna_seq_outputs.extend([
    f"{experiment_name}_results/all_samples_raw_counts.txt",
    f"{experiment_name}_results/all_samples_raw_counts.txt.summary",
    f"{experiment_name}_results/all_samples_counts_extended.tsv",
    f"{experiment_name}_results/all_samples_gene_symbols.tsv",
    f"{experiment_name}_results/multiqc_report.html",
    f"{experiment_name}_results/deseq2/normalized_counts.tsv"
])


rule all:
    input:
        rna_seq_outputs
